{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60eab798-28bc-4e7c-b3cb-a30af578c4a3",
      "metadata": {},
      "source": [
        "# Assignment 1: Modeling Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d69c6821-554e-41ec-aee7-0a5f46914b2f",
      "metadata": {},
      "source": [
        "By the end of this assignment, students will be able to implement and simulate spaced repetition algorithms, analyze recall behavior using aggregate statistics and visualizations, compare learning schedules using quantitative metrics, and design and justify a memory model based on empirical evidence.\n",
        "\n",
        "--------------------------------------------\n",
        "\n",
        "Welcome to the first TFT assignment! We will be working in Jupyter Notebook, which lets you write and run code in cells.\n",
        "\n",
        "**Jupyter tips (if you haven't used it before)**\n",
        "\n",
        "To run the currently selected cell (you can do either of the following):\n",
        "- Press Shift + Enter\n",
        "- Click the \u25b6 Run button in the toolbar\n",
        "  \n",
        "When a cell runs, its output appears directly below it. Make sure to save your progress as you go!\n",
        "\n",
        "When you edit a cell, it is affected by all the code you have run, even if you deleted it. If your notebook gets into a weird state, you can reset it by doing:\n",
        "- Click Kernel \u2192 Restart Kernel and Run up to Selected Cell\n",
        "\n",
        "**Run the follow 2 code blocks to setup the assignment and import the necessary libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "546d8b25-330d-48a5-b2fa-652e61d963da",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc69bc3-f447-4073-b475-66300243e78c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from a1 import srs, simulations\n",
        "from a1.mystery.mystery import MysteryLearner\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sns.set() # import default Seaborn plotting styles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ced8697-e546-4578-8cff-c99323d2eea0",
      "metadata": {},
      "source": [
        "# Part A: Learning About Learners\n",
        "\n",
        "We will start with a warmup that explores the API underlying this assignment, which simulates learners using a spaced repetition system (SRS). First, some quick background:\n",
        "\n",
        "A card is a single test item, similar to a flash card. Each card has a difficulty between 1 and 10, where harder cards take longer to learn. The card difficulty is **not** visible to the SRS, and is only used by the learner model. (An SRS can choose to *infer* card difficulty.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7888e53a-6e38-4cb2-ac75-bf6e9e1dc8f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "card = srs.Card(difficulty = 5.)\n",
        "card"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "572afd8f-6192-4513-8f63-f15bc9917b3f",
      "metadata": {},
      "source": [
        "A learner is a computational cognitive model of a person using an SRS. They take a card as an input, and attempt to learn it at intervals determined by the SRS. The `MysteryLearner` is the learner model you will work with for this assignment. Like working with real people, you will not get to see the source code of `MysteryLearner` directly, and instead must infer its properties through experimentation.\n",
        "\n",
        "*Note:* The `MysteryLearner` is mildly obscured by providing pre-compiled Python bytecode rather than Python source code. Please do not attempt to deobsfucate it, as that goes against the spirit of the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ee0152-0dd2-4b3e-a4e9-19c0f85900fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "learner = MysteryLearner(card, seed=0x1337BEEF) # seed allows deterministic regeneration of a learning trace\n",
        "learner"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b60933-12c6-4de2-9019-b33d64dc52f2",
      "metadata": {},
      "source": [
        "A learner makes a first attempt at a card, whose outcome is, for simplicity, decided by the simulation. Outcomes use the Anki model of ratings where a learner gets the card wrong (`Rating.AGAIN = 1`), or gets the card right with varying degrees of difficulty (`Rating.HARD = 2`, `Rating.GOOD = 3`, `Rating.EASY = 4`).\n",
        "\n",
        "Note that the learner is a *stateful* object, so running the next line changes the learner's internal memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93461de-e358-4160-869d-8ef7954e6867",
      "metadata": {},
      "outputs": [],
      "source": [
        "learner.initialize(rating = srs.Rating.AGAIN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f6013b-5224-45e0-a5ef-b64959fa01b8",
      "metadata": {},
      "source": [
        "Finally, the learner reviews the item again after a period of time dictated by the SRS. Conceptually, the parameter `dt` is in days, so if the review happens after 5 days, then `dt = 5`. Two things happen on calling `review`:\n",
        "1. The function returns a rating, representing the learner's attempt on the card.\n",
        "2. The function updates the state of the learner, representing the learner's strengthened memory after review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6cf9ba-3e1f-42ec-89dd-45185babec14",
      "metadata": {},
      "outputs": [],
      "source": [
        "learner.review(dt = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba2cf3a4-28d7-410f-bda5-f3714bad84cd",
      "metadata": {},
      "source": [
        "Putting these functions together, we can simulate a learner repeatedly reviewing an item over time. For example, say the learner reviews an item every 10 days for 300 days. We can represent that by repeatedly calling `learner.review(dt = 10)` and recording the result, as plotted below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cc277e-198b-4a04-b02a-4f52912d2311",
      "metadata": {},
      "outputs": [],
      "source": [
        "learner = MysteryLearner(card, seed=0x1337BEEF)\n",
        "learner.initialize(rating = srs.Rating.AGAIN)\n",
        "\n",
        "# pd is pandas, a library for working with tables (or \"data frames\").\n",
        "# The pandas documentation is here: https://pandas.pydata.org/pandas-docs/version/2.3/index.html\n",
        "ratings = pd.DataFrame([\n",
        "    {\n",
        "        \"time\": i * 10,\n",
        "        \"rating\": learner.review(dt = 10),\n",
        "    }\n",
        "    for i in range(30)\n",
        "])\n",
        "\n",
        "# sns is seaborn, a data visualization library. \n",
        "# The seaborn documentation is here: https://seaborn.pydata.org/tutorial.html\n",
        "ax = sns.scatterplot(data=ratings, x=\"time\", y=\"rating\")\n",
        "_ = ax.set_yticks(range(1, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d2478e-01dc-4eb1-990e-2dcdf9f29519",
      "metadata": {},
      "source": [
        "*Remember that rating = the learner's attempt on a card. 1 means the card was the most difficult, 4 means the card was easy. What does the plotted trend indicate?*\n",
        "\n",
        "Conversely, we can simulate a learner forgetting an item over time if they don't review it. In this example, we call the `recall_prob` function which computes the probability of recalling an item based on the time since the last review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b1c394-3122-45bc-9673-8181297a4da8",
      "metadata": {},
      "outputs": [],
      "source": [
        "learner = MysteryLearner(card, seed=0x1337BEEF)\n",
        "learner.initialize(rating = srs.Rating.EASY)\n",
        "learner.review(5)\n",
        "\n",
        "probs = pd.DataFrame([\n",
        "    {\n",
        "        \"time\": i * 10,\n",
        "        \"recall_prob\": learner.recall_prob(dt = i * 10),\n",
        "    }\n",
        "    for i in range(30)\n",
        "])\n",
        "\n",
        "sns.lineplot(data=probs, x=\"time\", y=\"recall_prob\")\n",
        "ax = sns.scatterplot(data=probs, x=\"time\", y=\"recall_prob\")\n",
        "_ = ax.set_ylim([-0.05, 1.05])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc0bbc1-5ebd-4700-a2e0-4f83dc160c0d",
      "metadata": {},
      "source": [
        "--------------------------------------------\n",
        "\n",
        "## Task 1 (15 points)\n",
        "\n",
        "Our goal is to understand the properties of an SRS in aggregate, so we will need to move from analyzing a single simulation to many simulations. Write a notebook cell which runs the simulation from the previous cell 1,000 times (without the fixed random seed, and with a random card each time). Then plot the resulting distribution of recall probabilities at each time step.\n",
        "\n",
        "**Notes:**\n",
        "- `Card.sample` is a static method which returns a card of random difficulty.\n",
        "- [`pd.concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) can combine multiple dataframes.\n",
        "- In Seaborn, you can ask it to visualize a dataframe which contains multiple `y` values for the same `x`. Seaborn will visualize either the *spread* of `y` at each `x` (e.g., inter-quartile range) or the *uncertainty* of `y` (e.g., confidence interval). You should be very careful to pick the appropriate visualization to your task. For this task, we recommend using a [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html). For later tasks, consider using [error bars](https://seaborn.pydata.org/tutorial/error_bars.html) such as a percentile interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b08e6e-ac7e-4892-b460-4187a790bbf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your answer goes here.\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c82226d-1f5c-4dc5-b6f8-bbf1a5ca3960",
      "metadata": {},
      "source": [
        "Answer the following questions:\n",
        "\n",
        "1. Describe the shape of the distribution. Are there tails or outliers? How does the shape reflect the fact that learners are reviewing cards of varying difficulty?\n",
        "2. Compare the recall probabilities of a single learner with card difficulty of 5 (the first plot) with the distribution of 1000 learners with random card difficulties. How does the distribution look different?\n",
        "3. Looking at the median of the boxplot, when would a learner's recall drop below 60%?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea79164e-095b-47eb-b143-183841e8f1c8",
      "metadata": {},
      "source": [
        "*Write your answer here.*\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bb42280-b2fd-4a9a-9190-5ca568115eae",
      "metadata": {},
      "source": [
        "--------------------------------------------\n",
        "\n",
        "The final piece of our SRS API is a schedule, which dictates when a learner reviews an item. The simplest schedule is **uniform**, which consistently reviews an item every $I$ days for some $I$, such as $I = 20$. A schedule is a subclass of `srs.Schedule`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da31048b-25e5-499f-84f9-3434d3c5c544",
      "metadata": {},
      "outputs": [],
      "source": [
        "class UniformSchedule(srs.Schedule):\n",
        "    def __init__(self, I):\n",
        "        self.I = I\n",
        "\n",
        "    def interval(self):\n",
        "        return self.I"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "386b7348-6552-4f4e-a444-4d154618f62a",
      "metadata": {},
      "source": [
        "We have provided you a simulation function which takes a schedule, and returns a trace of the mystery learner using the schedule over a year. The trace includes a row for every day, not just days where reviews occurred. Each row contains the time, recall probability, whether the review occurred, and the user's rating if the review occurred (NaN otherwise). Here's what a sample trace looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8194ac68-e574-4814-a0ff-b3335d2d3e6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# in this simulation, I = 20, meaning the mystery learner reviews items every 20 days.\n",
        "data = simulations.simulate(UniformSchedule, seed=0x1337BEEF, I=20)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f40fb6-8f40-4fda-b161-1da3518fa722",
      "metadata": {},
      "source": [
        "You can visualize this trace using Seaborn's `lineplot` function to produce an SRS's characteristic saw-tooth graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9818ad4-678b-4ecf-92b1-cce7f8bc9a65",
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.lineplot(data, x=\"time\", y=\"recall_prob\")\n",
        "_ = ax.set_ylim([-0.05, 1.05])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f433c508-5db9-4a78-8c07-c47874a1bcb3",
      "metadata": {},
      "source": [
        "The schedule can be updated every time the learner performs a review. The `Schedule.update` method takes the learner's rating and the time since last review. A simple updating schedule is an *expanding* schedule, which always doubles the review interval:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ef0d3b-fec7-4a9d-96b1-5ce5456324b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExpandingSchedule(srs.Schedule):\n",
        "    def __init__(self):\n",
        "        self.I = 1\n",
        "\n",
        "    def interval(self):\n",
        "        return self.I\n",
        "\n",
        "    def update(self, _rating, _dt):\n",
        "        self.I *= 2\n",
        "\n",
        "data = simulations.simulate(ExpandingSchedule, seed=0x1337BEEF)\n",
        "ax = sns.lineplot(data, x=\"time\", y=\"recall_prob\")\n",
        "_ = ax.set_ylim([-0.05, 1.05])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f4e5b9-edcd-43a4-9163-894c4ceeb442",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "----------\n",
        "\n",
        "## Task 2 (10 points)\n",
        "\n",
        "In a few sentences, explain how the difference in shape between the previous two graphs is related to the choice of schedule."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910ec16a-1ba4-49d8-b0b0-c0d02b70b1ca",
      "metadata": {},
      "source": [
        "*Your answer here.*\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7eaf2f9-a674-4ddc-8398-df7d71e4d993",
      "metadata": {},
      "source": [
        "--------\n",
        "\n",
        "Like before, we want to move from a single run to many simulations. The code below runs 1000 simulations using the expanding schedule (again removing the random seed), and visualizes the spread of results using a 75% percentile interval:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e762b0-ba15-4143-98b4-c316390bf748",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = simulations.simulate_many(ExpandingSchedule, N=1000)\n",
        "ax = sns.lineplot(data, x=\"time\", y=\"recall_prob\", estimator=\"median\", errorbar=(\"pi\", 75))\n",
        "_ = ax.set_ylim([-0.05, 1.05])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ce56a68-5e55-465d-87fb-07bfe1163ad9",
      "metadata": {},
      "source": [
        "------ \n",
        "\n",
        "## Task 3 (15 points)\n",
        "\n",
        "Imagine the learner had a test on day 100 and wants to cram for the test. Write a schedule that causes the learner to review on days 95-99, simulate it 1,000 times, and plot the recall probability over time like the cell above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d91bb4-9ec2-497f-bb8f-41af0f857ab1",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CrammingSchedule(srs.Schedule):\n",
        "    \"\"\"\n",
        "    A schedule that reviews frequently right before a fixed test date.\n",
        "    \n",
        "    Hint: interval() returns the number of days until the next review.\n",
        "    Hint: update() is called after each review and can update internal state\n",
        "          to change what interval() returns next.\n",
        "    \"\"\"\n",
        "    def interval(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def update(self, rating, dt):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d14630-b1b3-4616-b2f2-93ed61b258b5",
      "metadata": {},
      "source": [
        "**Answer the following question:**\n",
        "Using the percentile interval shown in the plot, what is the approximate range of recall probabilities at the end of the year?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c70fff-a530-4398-aa75-a30b568bbb88",
      "metadata": {},
      "source": [
        "*Your answer here.*\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193e7cf5-9b16-4147-a2d0-47c78c15229b",
      "metadata": {},
      "source": [
        "------ \n",
        "\n",
        "\n",
        "# Part B. Designing a Schedule\n",
        "\n",
        "No schedule is perfect, but some schedules are better than others, depending on your goals. The basic trade-off is effort vs. recall: how often a learner studies, versus how well they recall the material. Below, we run each existing schedule in simulation, and compute a variety of metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43412fd3-c6fe-4c63-b998-d9adee5e613e",
      "metadata": {},
      "outputs": [],
      "source": [
        "schedules = [\n",
        "    (UniformSchedule, {\"I\": 5}, \"uniform-5\"),\n",
        "    (UniformSchedule, {\"I\": 20}, \"uniform-20\"),\n",
        "    (UniformSchedule, {\"I\": 100}, \"uniform-100\"),\n",
        "    (CrammingSchedule, {}, \"cramming\"),\n",
        "    (ExpandingSchedule, {}, \"expanding\"),\n",
        "]\n",
        "\n",
        "metrics = pd.concat([\n",
        "    simulations.eval_metrics(simulations.simulate_many(Schedule, N=1000, **kwargs), name)\n",
        "    for (Schedule, kwargs, name) in schedules\n",
        "])\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc43715-b804-4d82-b8b9-a68141d38944",
      "metadata": {},
      "source": [
        "A first question is how can we summarize the effect of a schedule on recall? In our metrics, we track three kinds of recall. First, `exam_recall` is recall at time $T = 100$ of our hypothetical exam on day 100. Below, we plot the number of reviews (x-axis) against the exam recall (y-axis) of each schedule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f05431a7-2b06-4f22-98ea-c3355bcb3168",
      "metadata": {},
      "outputs": [],
      "source": [
        "simulations.scatterplot_annot(metrics, x=\"num_reviews\", y=\"exam_recall\", label=\"schedule\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b780be84-b877-4447-820e-9b5dbadffc6c",
      "metadata": {},
      "source": [
        "**Consider:** which direction on this plot is desirable? That is, we want schedules which move towards which quadrant?\n",
        "\n",
        "Clearly, cramming is the optimal strategy to maximize exam recall with respect to effort. Rather than looking at any individual day's recall, we can consider the average recall over all days of the year:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91404b6-84dd-464e-bcbf-589a5237ae73",
      "metadata": {},
      "outputs": [],
      "source": [
        "simulations.scatterplot_annot(metrics, x=\"num_reviews\", y=\"avg_recall\", label=\"schedule\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a89001-364d-45ab-a504-9cfcaeb00c43",
      "metadata": {},
      "source": [
        "This graph shows us our [Pareto frontier](https://en.wikipedia.org/wiki/Pareto_front). Our goal is to produce new algorithms which either:\n",
        "1. Given a number of reviews, increases recall. Or,\n",
        "2. Given a level of recall, decreases number of reviews.\n",
        "\n",
        "That is, we seek to move up and to the left.\n",
        "\n",
        "\n",
        "----------\n",
        "\n",
        "## Task 4 (20 points)\n",
        "\n",
        "To start, you will reimplement a known algorithm: SuperMemo-2, which we discussed in lecture. \n",
        "1. Implement the SM2 schedule, evaluate its recall metrics over 1,000 simulations (avg_recall and num_reviews), and plot its performance vs. our existing schedules on the previous scatterplot.\n",
        "2. Add an option to your SM2 implementation so that it does not use the \"easiness factor\", and instead fixes $EF = 2$. Evaluate the performance of this simplified algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2ec9f9-72bd-4523-8fc2-f64fe29b5958",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sm2(srs.Schedule):\n",
        "    \"\"\"\n",
        "    Implement SM-2.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_ef):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def interval(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def update(self, rating, dt):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# TODO: evaluate metrics for SM2 with EF and without EF (1,000 sims each)\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b858eb38-56db-49b5-a96e-58afc7bf914d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: add both to the existing scatterplot of schedules\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8541fab7-6e85-4200-86cd-8d380be119fa",
      "metadata": {},
      "source": [
        "Answer the following questions:\n",
        "1. Which schedules are **strictly** outperformed by SM2, meaning they are objectively worse than SM2 in terms of our two metrics?\n",
        "2. What is the difference between the performance of SM2 with and without the easiness factor? Why does removing the easiness factor cause this difference?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b6992f-be3b-41c0-9656-2e48a1e62970",
      "metadata": {},
      "source": [
        "*Your answer here.*\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f0bd6a7-2272-4997-9aff-a2d467b02c2e",
      "metadata": {},
      "source": [
        "----------------\n",
        "\n",
        "Your final challenge is going to be to design a new algorithm which outperforms SM-2. Rather than open-ended trial-and-error, we are going to narrow the problem in the style of modern SRS algorithms. Briefly, some context:\n",
        "\n",
        "Every SRS algorithm is trying to do two things. \n",
        "1. Figure out the **strength** of a person's memory for an item.\n",
        "2. Deduce the optimal **interval** to increase strength over time.\n",
        "\n",
        "Algorithms like SuperMemo-2 don't cleanly distinguish between these concerns. But it's possible to solve these problems independently, and then put them together. Consider trying to solve Problem #2, given a solution for Problem #1. That is, you have a model of memory, and want to deduce intervals. A simple approach (used for a while by Duolingo, I believe) is a **threshold schedule**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda18518-3e64-49fd-a039-a2fa237a19df",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ThresholdSchedule(srs.Schedule):\n",
        "    def __init__(self, model, threshold=0.95):\n",
        "        self.model = model\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def initialize(self, rating):\n",
        "        self.model.initialize(rating)\n",
        "\n",
        "    def interval(self):\n",
        "        for I in range(2, 365):\n",
        "            if self.model.recall_prob(I) < self.threshold:\n",
        "                return I - 1\n",
        "        return 365\n",
        "\n",
        "    def update(self, rating, dt):\n",
        "        self.model.update(rating, dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2830320-d3cc-4e11-b35e-43ad438ce995",
      "metadata": {},
      "source": [
        "A threshold schedule takes as input a model of someone's memory and a target threshold. The goal is to never let the user's recall accuracy drop below the threshold. The implementation of `interval` shows one approach to this goal. Increase the interval $I$ until recall drops below the threshold, and make that our next interval. (If you're curious about more sophisticated approaches than a threshold, see the [MEMORIZE algorithm](https://learning.mpi-sws.org/memorize/).)\n",
        "\n",
        "**Goal of threshold schedule: schedule the next review before recall drops below the threshold.**\n",
        "\n",
        "This schedule should perform well if given access to a \"gold standard\" model of the learner's memory. For example, below is a \"cheating\" simulation which instantiates `ThresholdSchedule` with exactly `MysteryLearner` given the sampled `Card`. Notice how the recall immediately jumps up after hitting 0.95, indicating that this threshold schedule is performing as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e19455-c396-49ff-9a3f-37406f4cfcc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = simulations.cheating_simulate(ThresholdSchedule, seed=0x1337BEEF)\n",
        "ax = sns.lineplot(data, x=\"time\", y=\"recall_prob\")\n",
        "_ = ax.set_ylim([0.85, 1.01]) # note the change in y-axis limits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a938b05-d50f-4b57-a193-8b4339c94c6a",
      "metadata": {},
      "source": [
        "However, your SRS doesn't get access to the actual learner, so you will have to make a proxy model for the learner's probability of recall. We will use a framework inspired by Duolingo's [halflife regression](https://research.duolingo.com/papers/settles.acl16.pdf) framework. In short, we can model the probability of recall with the equation:\n",
        "\n",
        "$$P(\\text{recall}) = 2^{-\\Delta / h}$$\n",
        "\n",
        "Where $\\Delta$ is the change in time (`dt`), and $h$ is the *half-life* of the memory, i.e., the amount of time it takes for recall to drop by 50%. A key intuition is that larger half-life means a stronger memory: if h is larger, the exponent \n",
        "$-\\Delta/h$ approaches $0$, so $2^{-\\Delta / h}$ approaches 1, i.e., recall decays more slowly over time. This equation is represented by the `HalflifeLearner`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb4eb47-74fc-4180-ae3a-1302edfb06c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalflifeLearner(srs.Learner):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def initialize(self, rating):\n",
        "        self.model.initialize(rating)\n",
        "        \n",
        "    def recall_prob(self, dt):\n",
        "        return 2 ** (-dt / self.model.h())\n",
        "\n",
        "    def update(self, rating, dt):\n",
        "        self.model.update(rating, dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e248550-7def-4171-9e36-093dabb6ae79",
      "metadata": {},
      "source": [
        "The challenge is to implement a model of `h` which updates based on the learner's behavior. A simple baseline is to reimplement a variant of the Leitner box algorithm, where the half-life doubles for every correct answer, and halves for every incorrect answer. That is implemented as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ed7a48-4c46-41d9-9fea-4f280ea086a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Leitner:\n",
        "    def __init__(self):        \n",
        "        self.n_right = 0\n",
        "        self.n_wrong = 0\n",
        "\n",
        "    def initialize(self, rating):\n",
        "        self.update(rating, 0)\n",
        "\n",
        "    def h(self):\n",
        "        return 2 ** (self.n_right - self.n_wrong)\n",
        "\n",
        "    def update(self, rating, _dt):\n",
        "        if rating > 1:\n",
        "            self.n_right += 1\n",
        "        else:\n",
        "            self.n_wrong += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec746151-10db-417f-96f9-cf30755cbaa1",
      "metadata": {},
      "source": [
        "If we simulate the threshold schedule using the halflife learner under the Leitner model, then our model is less effective than before at preventing recall from crossing the 0.95 threshold:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad8ccfc-1e8c-474b-a2ed-0f3bbe5d2f5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = simulations.simulate(lambda: ThresholdSchedule(HalflifeLearner(Leitner())), seed=0x1337BEEF)\n",
        "ax = sns.lineplot(data, x=\"time\", y=\"recall_prob\")\n",
        "_ = ax.set_ylim([0.85, 1.01])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122caeb3-3c32-4d92-8245-8e0e526d5234",
      "metadata": {},
      "source": [
        "We can summarize this difference in behavior using the metrics from before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5599b63-efc4-4852-ba1f-20426241f505",
      "metadata": {},
      "outputs": [],
      "source": [
        "ts_leitner_metrics = simulations.eval_metrics(simulations.simulate_many(\n",
        "    lambda: ThresholdSchedule(HalflifeLearner(Leitner())), N=1000), \"ts-leitner\")\n",
        "ts_ideal_metrics = simulations.eval_metrics(simulations.cheating_simulate_many(\n",
        "    ThresholdSchedule, N=1000), \"ts-ideal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39429493-ece3-46c0-a437-ccc0961fc02f",
      "metadata": {},
      "outputs": [],
      "source": [
        "simulations.scatterplot_annot(\n",
        "    pd.concat([sm2_ef_metrics, sm2_no_ef_metrics, ts_leitner_metrics, ts_ideal_metrics]), \n",
        "    x=\"num_reviews\", y=\"avg_recall\", label=\"schedule\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "827d0f94-0ff3-4cca-aeeb-86de7a02c918",
      "metadata": {},
      "source": [
        "Observe that `ts-leitner` is objectively worse than SM-2 (with EF), while `ts-ideal` is objectively better. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15984d7-9b43-4e11-9436-43bd70e285a3",
      "metadata": {},
      "source": [
        "# Task 5 (40 Points)\n",
        "\n",
        "Your challenge is to implement a half-life model which is as close as possible to `ts-ideal`. Some things to consider about the learner:\n",
        "\n",
        "1. A higher card difficulty leads to weaker memories (smaller half-life).\n",
        "2. The learner provides a rating from 1-4, and higher ratings indicate stronger memories.\n",
        "3. As in systems like Anki or Duolingo, you can generate large amounts of data that describe the mystery learner\u2019s recall probability under different conditions. You can analyze this data to understand its behavior, or use it to tune your model's parameters.\n",
        "\n",
        "Your grade on this task will be the number in the `score` column of the computed metrics, which combines review/recall metrics into a single number. Your score will vary across simulations, so run it with a high number (N=10000) to get a robust estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758368ab-d119-4f25-a557-a0ba839c3bde",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyModel:\n",
        "    def initialize(self, rating):\n",
        "        pass\n",
        "\n",
        "    def update(self, rating, dt):\n",
        "        pass\n",
        "\n",
        "    def h(self):\n",
        "        return 400.\n",
        "\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd1b1f7-f5c0-48c0-9ebb-d1ae61b6a20b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: add both to the existing scatterplot of schedules\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd2025d-408e-4b30-a1bd-7e9eb2f6dd75",
      "metadata": {},
      "source": [
        "**Before you're done:** make sure to run Kernel > Restart and Run All. Your notebook should run without errors from top-to-bottom.\n",
        "\n",
        "Once you've verified that's true, submit this file to Gradescope."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}